import streamlit as st
import requests
import json
import pandas as pd
from io import BytesIO
import base64
import re
from docx import Document # DOCX ì²˜ë¦¬ë¥¼ ìœ„í•´ ì¶”ê°€

# í˜ì´ì§€ êµ¬ì„± ë° API ì„¤ì •
st.set_page_config(page_title="ğŸ“„ Upstage Document Tool", layout="wide")
api_key = st.secrets["upstage_api_key"]
base_url = "https://api.upstage.ai/v1"

# ì‚¬ì´ë“œë°” ë„¤ë¹„ê²Œì´ì…˜
st.sidebar.title("ğŸ”§ ê¸°ëŠ¥ ì„ íƒ")
page = st.sidebar.radio("í˜ì´ì§€ ì„ íƒ", ["ë¬¸ì„œ íŒŒì‹±", "OCR"])

# ì§€ì› íŒŒì¼ í˜•ì‹
st.sidebar.markdown("### ğŸ“‹ ì§€ì› íŒŒì¼ í˜•ì‹")
st.sidebar.info("""
**í™•ì‹¤íˆ ì§€ì›:**
- PDF
- PNG, JPG, JPEG

**í…ŒìŠ¤íŠ¸ í•„ìš”:**
- HWP (í•œê¸€ ë¬¸ì„œ)
- DOCX (ì›Œë“œ)
- PPTX (íŒŒì›Œí¬ì¸íŠ¸)
- XLSX (ì—‘ì…€)
""")

# ê³µí†µ í—¤ë”
headers = {"Authorization": f"Bearer {api_key}"}

# HTMLì„ ë§ˆí¬ë‹¤ìš´ìœ¼ë¡œ ë³€í™˜í•˜ëŠ” í•¨ìˆ˜
def html_to_markdown(html_content):
    """HTMLì„ ë§ˆí¬ë‹¤ìš´ìœ¼ë¡œ ë³€í™˜"""
    # ì œëª© ë³€í™˜
    html_content = re.sub(r'<h1[^>]*>(.*?)</h1>', r'# \1', html_content)
    html_content = re.sub(r'<h2[^>]*>(.*?)</h2>', r'## \1', html_content)
    html_content = re.sub(r'<h3[^>]*>(.*?)</h3>', r'### \1', html_content)
    
    # ì¤„ë°”ê¿ˆ
    html_content = html_content.replace('<br>', '\n').replace('<br/>', '\n')
    
    # ë‹¨ë½
    html_content = re.sub(r'<p[^>]*>(.*?)</p>', r'\1\n\n', html_content)
    
    # ë³¼ë“œ
    html_content = re.sub(r'<strong>(.*?)</strong>', r'**\1**', html_content)
    html_content = re.sub(r'<b>(.*?)</b>', r'**\1**', html_content)
    
    # ì´íƒ¤ë¦­
    html_content = re.sub(r'<em>(.*?)</em>', r'*\1*', html_content)
    html_content = re.sub(r'<i>(.*?)</i>', r'*\1*', html_content)
    
    # ë‚˜ë¨¸ì§€ HTML íƒœê·¸ ì œê±°
    html_content = re.sub(r'<[^>]+>', '', html_content)
    
    return html_content.strip()

# í‘œ ì¶”ì¶œ í•¨ìˆ˜
def extract_tables_from_html(html_content):
    """HTMLì—ì„œ í‘œ ì¶”ì¶œ"""
    tables = []
    table_pattern = r'<table[^>]*>(.*?)</table>'
    table_matches = re.findall(table_pattern, html_content, re.DOTALL)
    
    for table_html in table_matches:
        rows = []
        row_pattern = r'<tr[^>]*>(.*?)</tr>'
        row_matches = re.findall(row_pattern, table_html, re.DOTALL)
        
        for row_html in row_matches:
            cells = []
            cell_pattern = r'<t[hd][^>]*>(.*?)</t[hd]>'
            cell_matches = re.findall(cell_pattern, row_html, re.DOTALL)
            
            for cell in cell_matches:
                clean_cell = re.sub(r'<[^>]+>', '', cell).strip()
                cells.append(clean_cell)
            
            if cells:
                rows.append(cells)
        
        if rows:
            tables.append(rows)
    
    return tables

# ì•ˆì „í•œ DataFrame ìƒì„± í•¨ìˆ˜
def safe_create_dataframe(table_data):
    """ì•ˆì „í•˜ê²Œ DataFrame ìƒì„±"""
    try:
        if not table_data:
            return pd.DataFrame()
        
        max_cols = 0
        if table_data: # Ensure table_data is not empty before finding max_cols
            # Filter out empty rows or rows with non-iterable elements before calculating max_cols
            valid_rows = [row for row in table_data if hasattr(row, '__len__')]
            if valid_rows:
                 max_cols = max(len(row) for row in valid_rows)
            else: # if all rows are invalid or table_data was initially empty after filtering
                return pd.DataFrame()


        normalized_data = []
        for row in table_data: # Iterate original table_data for normalization
            if hasattr(row, '__len__'): # Process only if row is iterable
                 normalized_row = list(row) + [''] * (max_cols - len(row)) # Ensure row is list for extendability
                 normalized_data.append(normalized_row)
            # else: skip rows that are not iterable or handle as error/empty

        if not normalized_data: # If no data could be normalized
            return pd.DataFrame()

        if len(normalized_data) > 1 and len(normalized_data[0]) == max_cols:
            df = pd.DataFrame(normalized_data[1:], columns=normalized_data[0])
        else:
            df = pd.DataFrame(normalized_data)
        
        return df
        
    except Exception as e:
        st.error(f"DataFrame ìƒì„± ì˜¤ë¥˜: {str(e)}")
        return pd.DataFrame(table_data) # Fallback to original data if error

# í…ìŠ¤íŠ¸ë¥¼ DOCX íŒŒì¼ ë°”ì´íŠ¸ë¡œ ë³€í™˜í•˜ëŠ” í•¨ìˆ˜
def text_to_docx_bytes(text_content):
    doc = Document()
    doc.add_paragraph(text_content)
    bio = BytesIO()
    doc.save(bio)
    bio.seek(0)
    return bio.getvalue()

# â”€â”€â”€ ë¬¸ì„œ íŒŒì‹± í˜ì´ì§€ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
if page == "ë¬¸ì„œ íŒŒì‹±":
    st.header("ğŸ“„ ë¬¸ì„œ íŒŒì‹± (Document Parsing)")
    
    uploaded_file = st.file_uploader(
        "ë¬¸ì„œ íŒŒì¼ ì—…ë¡œë“œ", 
        type=["pdf", "png", "jpg", "jpeg", "hwp", "docx", "pptx", "xlsx"],
        help="PDFì™€ ì´ë¯¸ì§€ëŠ” í™•ì‹¤íˆ ì§€ì›ë©ë‹ˆë‹¤. HWP, DOCX ë“±ì€ í…ŒìŠ¤íŠ¸ê°€ í•„ìš”í•©ë‹ˆë‹¤."
    )
    
    if uploaded_file:
        col1, col2, col3 = st.columns(3)
        with col1:
            st.metric("íŒŒì¼ëª…", uploaded_file.name)
        with col2:
            st.metric("íŒŒì¼ í¬ê¸°", f"{uploaded_file.size / 1024:.1f} KB")
        with col3:
            file_ext = uploaded_file.name.split('.')[-1].upper()
            st.metric("íŒŒì¼ í˜•ì‹", file_ext)
        
        col1_opts, col2_opts = st.columns(2) # Renamed to avoid conflict with col1, col2 above
        with col1_opts:
            encode_option = st.selectbox(
                "Base64 ì¸ì½”ë”© ì˜µì…˜",
                ["ì—†ìŒ", "í‘œë§Œ", "í…ìŠ¤íŠ¸ë§Œ", "í…ìŠ¤íŠ¸ì™€ í‘œ", "ëª¨ë“  ìš”ì†Œ"],
                key=f"encode_opt_{uploaded_file.name}"
            )
        with col2_opts:
            output_format = st.multiselect(
                "ì¶œë ¥ í˜•ì‹",
                ["html", "text", "markdown"],
                default=["html"],
                key=f"output_fmt_{uploaded_file.name}"
            )
        
        with st.expander("âš™ï¸ ê³ ê¸‰ ì˜µì…˜"):
            col1_adv, col2_adv = st.columns(2) # Renamed for clarity
            with col1_adv:
                ocr_mode = st.selectbox(
                    "OCR ëª¨ë“œ",
                    ["auto (ìë™)", "force (ê°•ì œ)"],
                    help="auto: í•„ìš”ì‹œì—ë§Œ OCR, force: í•­ìƒ OCR",
                    key=f"ocr_mode_{uploaded_file.name}"
                )
                coordinates = st.checkbox("ì¢Œí‘œ ì •ë³´ í¬í•¨", value=True, key=f"coords_{uploaded_file.name}")
            with col2_adv:
                chart_recognition = st.checkbox("ì°¨íŠ¸ ì¸ì‹", value=True, key=f"chart_recog_{uploaded_file.name}")
        
        api_data = { # Renamed 'data' to 'api_data'
            "ocr": ocr_mode.split()[0],
            "model": "document-parse",
            "coordinates": str(coordinates).lower(),
            "chart_recognition": str(chart_recognition).lower()
        }
        
        if output_format:
            api_data["output_formats"] = str(output_format).replace("'", '"')
        
        if encode_option == "í…ìŠ¤íŠ¸ë§Œ":
            api_data["base64_encoding"] = '["text"]'
        elif encode_option == "í‘œë§Œ":
            api_data["base64_encoding"] = '["table"]'
        elif encode_option == "í…ìŠ¤íŠ¸ì™€ í‘œ":
            api_data["base64_encoding"] = '["text","table"]'
        elif encode_option == "ëª¨ë“  ìš”ì†Œ":
            api_data["base64_encoding"] = '["text","table","figure","chart","diagram","heading1","heading2","heading3","paragraph","list"]'
        
        with st.expander("ğŸ“‹ API íŒŒë¼ë¯¸í„° í™•ì¸"):
            st.json(api_data)
        
        if st.button("ğŸš€ íŒŒì‹± ì‹¤í–‰", type="primary", key=f"parse_btn_{uploaded_file.name}"):
            with st.spinner(f"{file_ext} íŒŒì¼ íŒŒì‹± ì¤‘..."):
                files_payload = {"document": (uploaded_file.name, uploaded_file.read(), uploaded_file.type)} # Renamed 'files'
                resp = requests.post(f"{base_url}/document-digitization", headers=headers, files=files_payload, data=api_data)
            
            if resp.ok:
                result = resp.json()
                st.success(f"âœ… {file_ext} íŒŒì¼ íŒŒì‹± ì„±ê³µ!")
                
                res_col1, res_col2, res_col3 = st.columns(3) # Renamed for summary
                with res_col1:
                    st.metric("ì¶”ì¶œëœ ìš”ì†Œ", len(result.get("elements", [])))
                with res_col2:
                    st.metric("ì²˜ë¦¬ëœ í˜ì´ì§€", result.get("usage", {}).get("pages", 0))
                with res_col3:
                    categories = {}
                    for elem in result.get("elements", []):
                        cat = elem.get("category", "unknown")
                        categories[cat] = categories.get(cat, 0) + 1
                    st.metric("ìš”ì†Œ íƒ€ì…", len(categories))
                
                tabs = st.tabs(["ğŸ“„ ë¬¸ì„œ ë·°", "ğŸ“Š í‘œ ì¶”ì¶œ", "ğŸ“ ë§ˆí¬ë‹¤ìš´", "ğŸ–¼ï¸ ì´ë¯¸ì§€/ë„í‘œ", "ğŸ’¾ ë‹¤ìš´ë¡œë“œ", "ğŸ” ì›ë³¸ ë°ì´í„°"])
                
                html_content = result.get("content", {}).get("html", "")
                markdown_content = result.get("content", {}).get("markdown", "")
                if not markdown_content and html_content:
                    markdown_content = html_to_markdown(html_content)

                with tabs[0]:
                    st.subheader("ë Œë”ë§ëœ ë¬¸ì„œ")
                    if html_content:
                        styled_html = f"""
                        <style>
                            .parsed-content {{ font-family: 'Noto Sans KR', sans-serif; line-height: 1.6; max-width: 900px; margin: 0 auto; padding: 30px; background: white; border-radius: 10px; box-shadow: 0 2px 20px rgba(0,0,0,0.1);}}
                            .parsed-content h1 {{ color: #1a1a1a; border-bottom: 3px solid #0066cc; padding-bottom: 10px; margin: 30px 0 20px 0; font-size: 28px;}}
                            .parsed-content h2 {{ color: #333; margin: 25px 0 15px 0; font-size: 22px;}}
                            .parsed-content h3 {{ color: #555; margin: 20px 0 10px 0; font-size: 18px;}}
                            .parsed-content p {{ margin: 15px 0; line-height: 1.8; color: #444;}}
                            .parsed-content table {{ border-collapse: collapse; width: 100%; margin: 20px 0; box-shadow: 0 2px 10px rgba(0,0,0,0.1);}}
                            .parsed-content th, .parsed-content td {{ border: 1px solid #ddd; padding: 12px; text-align: left;}}
                            .parsed-content th {{ background-color: #0066cc; color: white; font-weight: bold;}}
                            .parsed-content tr:nth-child(even) {{ background-color: #f8f9fa;}}
                            .parsed-content tr:hover {{ background-color: #e9ecef;}}
                        </style>
                        <div class="parsed-content">{html_content}</div>"""
                        st.markdown(styled_html, unsafe_allow_html=True)
                    else:
                        st.info("HTML ì½˜í…ì¸ ê°€ ì—†ìŠµë‹ˆë‹¤.")
                
                with tabs[1]:
                    st.subheader("ì¶”ì¶œëœ í‘œ")
                    tables = extract_tables_from_html(html_content)
                    if tables:
                        for i, table_data in enumerate(tables):
                            st.write(f"### í‘œ {i+1}")
                            df = safe_create_dataframe(table_data)
                            if not df.empty:
                                st.dataframe(df, use_container_width=True)
                                df_col1, df_col2 = st.columns(2) # Renamed
                                with df_col1:
                                    csv_data = df.to_csv(index=False, encoding='utf-8-sig').encode('utf-8-sig') # Renamed 'csv'
                                    st.download_button(f"ğŸ’¾ CSV ë‹¤ìš´ë¡œë“œ", csv_data, f"table_{i+1}.csv", "text/csv", key=f"csv_{i}_{uploaded_file.name}")
                                with df_col2:
                                    try:
                                        buffer = BytesIO()
                                        with pd.ExcelWriter(buffer, engine='xlsxwriter') as writer:
                                            df.to_excel(writer, index=False, sheet_name=f'Table_{i+1}')
                                        buffer.seek(0)
                                        st.download_button(f"ğŸ’¾ Excel ë‹¤ìš´ë¡œë“œ", buffer, f"table_{i+1}.xlsx", "application/vnd.openxmlformats-officedocument.spreadsheetml.sheet", key=f"excel_{i}_{uploaded_file.name}")
                                    except Exception as e:
                                        st.error(f"Excel ë³€í™˜ ì˜¤ë¥˜: {str(e)}")
                            else:
                                st.warning(f"í‘œ {i+1}ì„ DataFrameìœ¼ë¡œ ë³€í™˜í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                                st.text("ì›ë³¸ ë°ì´í„°:")
                                for row in table_data:
                                    st.text(" | ".join(str(cell) for cell in row)) # Ensure cells are strings
                    else:
                        st.info("ì¶”ì¶œëœ í‘œê°€ ì—†ìŠµë‹ˆë‹¤.")
                
                with tabs[2]:
                    st.subheader("ë§ˆí¬ë‹¤ìš´ ë³€í™˜")
                    if markdown_content:
                        st.markdown("### ë¯¸ë¦¬ë³´ê¸°")
                        st.markdown(markdown_content)
                        st.markdown("### í¸ì§‘")
                        edited_md = st.text_area("ë§ˆí¬ë‹¤ìš´ í¸ì§‘", markdown_content, height=400, key=f"md_edit_{uploaded_file.name}")
                        if edited_md != markdown_content:
                            st.download_button("ğŸ’¾ í¸ì§‘ëœ ë§ˆí¬ë‹¤ìš´ ë‹¤ìš´ë¡œë“œ", edited_md.encode('utf-8'), f"{uploaded_file.name.split('.')[0]}_edited.md", "text/markdown", key=f"md_download_edited_{uploaded_file.name}")
                    else:
                        st.info("ë§ˆí¬ë‹¤ìš´ ì½˜í…ì¸ ê°€ ì—†ìŠµë‹ˆë‹¤.")
                
                with tabs[3]:
                    st.subheader("ì¶”ì¶œëœ ì´ë¯¸ì§€ ë° ë„í‘œ")
                    image_elements = [elem for elem in result.get("elements", []) if elem.get("base64_encoding")]
                    if image_elements:
                        for i, elem in enumerate(image_elements):
                            cat = elem.get("category", "unknown")
                            st.write(f"### {cat.upper()} {i+1}")
                            try:
                                img_data = base64.b64decode(elem["base64_encoding"])
                                st.image(img_data, use_column_width=True)
                                st.download_button(f"ğŸ’¾ {cat}_{i+1} ë‹¤ìš´ë¡œë“œ", img_data, f"{cat}_{i+1}.png", "image/png", key=f"img_{i}_{uploaded_file.name}")
                            except Exception as e:
                                st.error(f"ì´ë¯¸ì§€ ë””ì½”ë”© ì˜¤ë¥˜: {str(e)}")
                            st.divider()
                    else:
                        st.info("Base64 ì¸ì½”ë”©ëœ ì´ë¯¸ì§€ê°€ ì—†ìŠµë‹ˆë‹¤. Base64 ì¸ì½”ë”© ì˜µì…˜ì„ ì„¤ì •í•´ì£¼ì„¸ìš”.")
                
                with tabs[4]:
                    st.subheader("ì „ì²´ ë¬¸ì„œ ë‹¤ìš´ë¡œë“œ")
                    dl_all_col1, dl_all_col2, dl_all_col3 = st.columns(3) # Renamed
                    with dl_all_col1:
                        if html_content:
                            full_html = f"""<!DOCTYPE html><html><head><meta charset="UTF-8"><title>{uploaded_file.name} - Parsed</title><style>body {{ font-family: 'Malgun Gothic', sans-serif; margin: 40px; line-height: 1.6;}} table {{ border-collapse: collapse; width: 100%; }} th, td {{ border: 1px solid #ddd; padding: 8px; }} th {{ background-color: #4CAF50; color: white; }}</style></head><body>{html_content}</body></html>"""
                            st.download_button("ğŸ“„ HTML ë‹¤ìš´ë¡œë“œ", full_html.encode('utf-8'), f"{uploaded_file.name.split('.')[0]}_parsed.html", "text/html", key=f"html_full_download_{uploaded_file.name}")
                    with dl_all_col2:
                        if markdown_content:
                            st.download_button("ğŸ“ ë§ˆí¬ë‹¤ìš´ ë‹¤ìš´ë¡œë“œ", markdown_content.encode('utf-8'), f"{uploaded_file.name.split('.')[0]}_parsed.md", "text/markdown", key=f"md_full_download_{uploaded_file.name}")
                    with dl_all_col3:
                        json_str = json.dumps(result, ensure_ascii=False, indent=2)
                        st.download_button("ğŸ” JSON ë‹¤ìš´ë¡œë“œ", json_str.encode('utf-8'), f"{uploaded_file.name.split('.')[0]}_parsed.json", "application/json", key=f"json_full_download_{uploaded_file.name}")
                
                with tabs[5]:
                    st.subheader("ì›ë³¸ JSON ì‘ë‹µ")
                    st.json(result)
            else:
                st.error(f"âŒ íŒŒì‹± ì‹¤íŒ¨: {resp.status_code}")
                try:
                    error_msg = resp.json()
                except json.JSONDecodeError: # More specific exception
                    error_msg = resp.text
                st.error(f"ì˜¤ë¥˜ ë©”ì‹œì§€: {error_msg}")
                if file_ext == "HWP":
                    st.info("""ğŸ’¡ **HWP íŒŒì¼ ì˜¤ë¥˜ í•´ê²° ë°©ë²•:**\n1. HWPë¥¼ PDFë¡œ ë³€í™˜ í›„ ì—…ë¡œë“œ\n2. í•œê¸€ í”„ë¡œê·¸ë¨ì—ì„œ "ë‹¤ë¥¸ ì´ë¦„ìœ¼ë¡œ ì €ì¥" â†’ PDF ì„ íƒ\n3. ì˜¨ë¼ì¸ HWPâ†’PDF ë³€í™˜ ì„œë¹„ìŠ¤ ì´ìš©""")

# â”€â”€â”€ OCR í˜ì´ì§€ (ìˆ˜ì •ë¨) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
elif page == "OCR":
    st.header("ğŸ” OCR (í…ìŠ¤íŠ¸ ì¶”ì¶œ)")
    
    uploaded_files = st.file_uploader(
        "ë¬¸ì„œ/ì´ë¯¸ì§€ íŒŒì¼ ì—…ë¡œë“œ (ì—¬ëŸ¬ íŒŒì¼ ì„ íƒ ê°€ëŠ¥)", 
        type=["pdf", "png", "jpg", "jpeg", "hwp", "docx"],
        accept_multiple_files=True,
        help="ì´ë¯¸ì§€ë‚˜ ìŠ¤ìº”ëœ ë¬¸ì„œì—ì„œ í…ìŠ¤íŠ¸ë¥¼ ì¶”ì¶œí•©ë‹ˆë‹¤. ì—¬ëŸ¬ íŒŒì¼ì„ í•œ ë²ˆì— ì˜¬ë¦´ ìˆ˜ ìˆìŠµë‹ˆë‹¤."
    )
    
    if uploaded_files:
        for uploaded_file_item in uploaded_files: # Changed loop variable name
            with st.expander(f"ğŸ“„ {uploaded_file_item.name} ({(uploaded_file_item.size / 1024):.1f} KB) ê²°ê³¼", expanded=True):
                
                files_data_ocr = {"document": (uploaded_file_item.name, uploaded_file_item.read(), uploaded_file_item.type)} # Renamed
                
                api_params_ocr = { # Renamed
                    "ocr": "force",
                    "model": "document-parse"
                }
                
                button_key_ocr = f"ocr_button_{uploaded_file_item.name}_{uploaded_file_item.size}" # Added size for more uniqueness
                if st.button("ğŸ” OCR ì‹¤í–‰", type="primary", key=button_key_ocr):
                    with st.spinner(f"{uploaded_file_item.name} í…ìŠ¤íŠ¸ ì¶”ì¶œ ì¤‘..."):
                        resp = requests.post(f"{base_url}/document-digitization", headers=headers, files=files_data_ocr, data=api_params_ocr)
                    
                    if resp.ok:
                        result_ocr = resp.json() # Renamed
                        st.success(f"âœ… {uploaded_file_item.name}: OCR ì™„ë£Œ!")
                        
                        html_content_ocr = result_ocr.get("content", {}).get("html", "") # Renamed
                        text_content_ocr = result_ocr.get("content", {}).get("text", "") # Renamed
                        
                        if not text_content_ocr and html_content_ocr:
                            temp_text = html_content_ocr.replace('<br>', '\n').replace('<br/>', '\n')
                            temp_text = re.sub(r'<p[^>]*>(.*?)</p>', r'\1\n', temp_text) 
                            temp_text = re.sub('<[^<]+?>', '', temp_text) 
                            text_content_ocr = re.sub(r'[ \t]+', ' ', temp_text).strip()
                            text_content_ocr = "\n".join([line.strip() for line in text_content_ocr.splitlines() if line.strip()])

                        if text_content_ocr:
                            ocr_stat_col1, ocr_stat_col2, ocr_stat_col3 = st.columns(3) # Renamed
                            with ocr_stat_col1:
                                st.metric("ì´ ë¬¸ì ìˆ˜", f"{len(text_content_ocr):,}", key=f"char_cnt_{uploaded_file_item.name}_{uploaded_file_item.size}")
                            with ocr_stat_col2:
                                st.metric("ë‹¨ì–´ ìˆ˜", f"{len(text_content_ocr.split()):,}", key=f"word_cnt_{uploaded_file_item.name}_{uploaded_file_item.size}")
                            with ocr_stat_col3:
                                st.metric("ì¤„ ìˆ˜", f"{len(text_content_ocr.splitlines()):,}", key=f"line_cnt_{uploaded_file_item.name}_{uploaded_file_item.size}")
                            
                            st.subheader("ì¶”ì¶œëœ í…ìŠ¤íŠ¸")
                            st.text_area(
                                label="ì¶”ì¶œëœ í…ìŠ¤íŠ¸ ë‚´ìš©:", # Changed label from " "
                                value=text_content_ocr, 
                                height=300, 
                                key=f"text_area_{uploaded_file_item.name}_{uploaded_file_item.size}", 
                                disabled=True
                            )
                            
                            st.markdown("##### ğŸ’¾ ë‹¤ìš´ë¡œë“œ")
                            ocr_dl_col1, ocr_dl_col2 = st.columns(2) # Renamed
                            with ocr_dl_col1:
                                st.download_button(
                                    label="TXT íŒŒì¼ (.txt)",
                                    data=text_content_ocr.encode('utf-8'),
                                    file_name=f"{uploaded_file_item.name.split('.')[0]}_ocr.txt",
                                    mime="text/plain",
                                    key=f"txt_dl_{uploaded_file_item.name}_{uploaded_file_item.size}"
                                )
                            with ocr_dl_col2:
                                try:
                                    docx_bytes = text_to_docx_bytes(text_content_ocr)
                                    st.download_button(
                                        label="Word íŒŒì¼ (.docx)",
                                        data=docx_bytes,
                                        file_name=f"{uploaded_file_item.name.split('.')[0]}_ocr.docx",
                                        mime="application/vnd.openxmlformats-officedocument.wordprocessingml.document",
                                        key=f"docx_dl_{uploaded_file_item.name}_{uploaded_file_item.size}"
                                    )
                                except Exception as e:
                                    st.error(f"DOCX ë³€í™˜ ì˜¤ë¥˜: {e}")
                        else:
                            st.info("ì¶”ì¶œëœ í…ìŠ¤íŠ¸ê°€ ì—†ìŠµë‹ˆë‹¤.")
                            st.json(result_ocr)

                    else:
                        st.error(f"âŒ {uploaded_file_item.name}: OCR ì‹¤íŒ¨ (ìƒíƒœ ì½”ë“œ: {resp.status_code})")
                        try:
                            error_detail = resp.json()
                        except json.JSONDecodeError: # More specific exception
                            error_detail = resp.text
                        st.error(f"ì˜¤ë¥˜ ë‚´ìš©: {error_detail}")
                st.divider()
    else:
        st.info("OCRì„ ì‹¤í–‰í•  íŒŒì¼ì„ ì—…ë¡œë“œí•´ì£¼ì„¸ìš”.")
